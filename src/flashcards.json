[
  {
    "back": "Taylor series is the infinite series:<br><br>\n$$\nf(x) = \\sum_{n=0}^{\\inf}{\\frac{f^{(n)}(a)}{n!}(x - a)^{n}}\n$$\n<br><br>\nTaylor series \"expansion\" of a function typically implies truncation, meaning we approximate the function $f(x)$ by a finite number of terms. <br><br>\n$$\nf(x) \\approx f(a) + f^{\\prime}(a)(x-a) + \\dots + \\frac{f^{(N)}(a)}{N!} (x-a)^N.\n$$\n<br><br>",
    "front": "Taylor series of $f(x)$ at a point $x = a$ <br><br>\nvs. <br><br>\nTaylor series expansion of $f(x)$ at / around a point $x = a$<br>",
    "importance": 2,
    "tags": [
      "18.065",
      "16.32"
    ],
    "understanding": 2
  },
  {
    "back": "something",
    "front": "$$\nA^{\\top} \\cdot B\n$$\n\n<div style=\"width: 100%; height: 100%;\"><img class=\"embedded-card-image\" src=\"/assets/Screenshot_2025-03-02_at_11.05.44_PM.png\"></div>",
    "id": 1740974681658,
    "tags": [
      "1234.56"
    ],
    "understanding": 1
  },
  {
    "back": "Positive semi-definite matrix is defined as <br><br>\n$$\nx^T A x \\geq 0, \\quad \\forall x \\in \\mathbb{R}^n\n$$\n<br><br>",
    "front": "Positive semi-definite (PSD) <br><br>\nDefine<br><br>\nHow to test for it",
    "id": 1740891113103,
    "tags": [
      "18.065",
      "16.32"
    ],
    "understanding": 2
  },
  {
    "back": "A set of vectors that perfectly describes the space. <br><br>\n\nTheir combinations give one and only one way to produce every vector in the space.",
    "front": "Basis",
    "id": 1740885744839,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "<div style=\"width: 100%; height: 100%;\"><img class=\"embedded-card-image\" src=\"/assets/four_fundamental_subspaces.jpeg\"></div>\n<br>\nDimensions: <br>\n$Col(A) \\in \\mathbb{R}^{r}$ <br>\n$Null(A) \\in \\mathbb{R}^{n - r}$ <br>\n$Col(A^T) \\in \\mathbb{R}^{r}$ <br>\n$Null(A) \\in \\mathbb{R}^{m - r}$ <br>",
    "front": "Four fundamental subspaces.",
    "id": 1740884070112,
    "tags": [
      "18.065"
    ],
    "understanding": 2
  },
  {
    "back": "TODO: New back content",
    "front": "Card for mom",
    "id": 1740894978704,
    "tags": [
      "14.13"
    ],
    "understanding": 3
  },
  {
    "back": "- denoted $Col(A) = C(A)$ <br>\n- the column space is a subspace of $\\mathbb{R}^m$ ($A \\in \\mathbb{R}^{n \\times m}$)<br>\n- consists of all linear combinations of $A$'s columns <br>\n- this is captured by the space spanned by $b$ in $Ax = b, \\, \\forall x$",
    "front": "Column space of $A$",
    "id": 1740886684323,
    "tags": [
      "18.065"
    ],
    "understanding": 3
  },
  {
    "back": "- denoted $Col(A^T) = C(A)$, <br>\n- the column space is a subspace of $\\mathbb{R}^n$ (recall $A \\in \\mathbb{R}^{n \\times m}$)<br>\n- consists of all linear combinations of the columns of $A^T$'s <br>\n- this is captured by the space spanned by $b$ in $A^Ty = b, \\, \\forall y$",
    "front": "Row space of $A$ <br><br>",
    "id": 1740887337718,
    "tags": [
      "18.065",
      "hello"
    ],
    "understanding": 2
  },
  {
    "back": "- contains all the solutions $x$ to $Ax = 0$, including $x = 0$.",
    "front": "Null space of $A$",
    "id": 1740887782700,
    "tags": [
      "18.065"
    ],
    "understanding": 2
  },
  {
    "back": "<u><b>Definition</b></u> <br>\n<p> \nFor matrix $A \\in \\mathbb{R}^{m \\times n}$, vector $x \\in \\mathbb{R}^{n} \\setminus\\{0\\}$, and scalar $\\lambda \\in \\mathbb{R}$ the eigenvalues $\\lambda$ and eigenvectors $x$ are such that $Ax = \\lambda x$ \n</p> \n<br>\n\n<u><b>Procedure</b></u> <br>\n<ol>\n    <li>Rearrange to \\( (A - \\lambda I)x = 0 \\)</li>\n    <li>If \\( x \\) is non-zero, the equation will only have a solution if \\( \\mid A - \\lambda I \\mid = 0 \\)</li>\n    <li>Therefore, solve for \\( \\lambda \\) values such that \\( (A - \\lambda I) = 0 \\)</li>\n    <li>Substitute \\( \\lambda \\) values into \\( (A - \\lambda I)x = 0 \\) and use the system of equations to solve for the variable elements of vector \\( x \\)</li>\n</ol>",
    "front": "Eigenvalues and eigenvectors <br><br>\nDefine <br><br>\nProcedure",
    "id": 1740890671935,
    "tags": [
      "18.065",
      "16.32"
    ],
    "understanding": 2
  },
  {
    "back": "TODO: New back content",
    "front": "Gauss elimination",
    "id": 1740890812452,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "<ul>\n  <li>Denoted $rref(A)$</li>\n  <li>Rules:\n    <ol>\n      <li>Each leading 1 (pivot) is the only nonzero entry in its column.</li>\n      <li>The leading 1 in each row appears to the right of the leading 1 in the row above.</li>\n      <li>Any rows of all zeros appear in the bottom rows of the matrix.</li>\n    </ol>\n  </li>\n  <li>The first $r$ pivot columns form an identity-like structure.</li>\n  <li>The remaining $n - r$ columns, denoted as $F$, contain the free variables.</li>\n</ul>",
    "front": "Reduced row echelon form",
    "id": 1740887871355,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "To solve $Ax = b$ is to <u>express b as a linear combination of the columns of $A$.</u>",
    "front": "To solve $Ax = b$ is to ____.",
    "id": 1740886790619,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "The equations $Ax = b$ are solvable iff <u>${b}$ is in the column space of $A$</u>",
    "front": "The equations $Ax = b$ are solvable iff ____.",
    "id": 1740887017912,
    "tags": [
      "18.065"
    ],
    "understanding": 2
  },
  {
    "back": "Inner product / dot product as implied by the multiplication of a transposed column vector $1 \\times n$ and a column vector $n \\times 1$.<br><br>\n\nThe dot product is given by: <br><br>\n$$\n\\mathbf{a}^\\top \\mathbf{b} =\n\\begin{bmatrix} a_1 & a_2 & \\dots & a_n \\end{bmatrix}\n\\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix} =\n\\sum_{i=1}^{n} a_i b_i\n$$",
    "front": "Let  $\\mathbf{a}$  and  $\\mathbf{b}$  be column vectors in $\\mathbb{R}^n$. <br><br>\n\nWhat is $a^\\top b$ ?\n",
    "id": 1740895695348,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "Invertible matrix",
    "id": 1740887674549,
    "tags": [
      "18.065"
    ],
    "understanding": 2
  },
  {
    "back": "TODO: New back content",
    "front": "Singular matrix",
    "id": 1740887684118,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "Orthogonal matrix",
    "id": 1740887687921,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "<div style=\"width: 100%; height: 100%;\"><img class=\"embedded-card-image\" src=\"/assets/five_factorizations.jpeg\"></div>",
    "front": "The five factorizations of a matrix.",
    "id": 1740884244261,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "Procedure for QR factorization",
    "id": 1740890854848,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "Definition: factorization of $A$ into upper $U$ and lower $L$ triangular matrices.\n\n<br><br>\nExample a  $3 \\times 3$  matrix: <br><br>\n$$\nA =\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n$$\n\n<br><br>\nLU decomposition gives: <br><br>\n$$\nL =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\nl_{21} & 1 & 0 \\\\\nl_{31} & l_{32} & 1\n\\end{bmatrix},\n\\quad\nU =\n\\begin{bmatrix}\nu_{11} & u_{12} & u_{13} \\\\\n0 & u_{22} & u_{23} \\\\\n0 & 0 & u_{33}\n\\end{bmatrix}\n$$\n\n<br><br>\nApplication: solving linear systems.\n<br><br>\n\nProcedure:\n<div style=\"width: 100%; height: 100%;\"><img class=\"embedded-card-image\" src=\"/assets/Screenshot_2025-03-02_at_1.34.36_AM.png\"></div>",
    "front": "$LU$ decomposition <br><br>\nDefine <br><br>\nApplications <br><br>\nProcedure",
    "id": 1740890882881,
    "tags": [
      "18.065"
    ],
    "understanding": 3
  },
  {
    "back": "TODO: New back content",
    "front": "Procedure for singular value decomposition",
    "id": 1740890913235,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "Prove that for any matrix $A \\in R^{m\u00d7n}$, that $A^{T}A$ and $A$ have\nthe same null space.",
    "id": 1740890964079,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "Symmetric matrix",
    "id": 1740890063445,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "Propose a function $x = linear\\_solver(U, b)$, where $U \\in R^{n \\times n}$ is an upper triangular matrix, $b \\in R^n$ is a vector, and $x \\in R^n$ is the solution to $Ux = b$. <br><br>\n\nThen apply your procedure to",
    "id": 1740891657888,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "The power method",
    "id": 1740891867068,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "<div style=\"width: 100%; height: 100%;\"><img class=\"embedded-card-image\" src=\"/assets/IMG_3E1D74CC9C45-1.jpeg\"></div>",
    "front": "Similar matrix",
    "id": 1740892885417,
    "tags": [
      "18.065"
    ],
    "understanding": 1
  },
  {
    "back": "The Taylor series for a vector-valued function \\( F(x) \\) expands it around \\( x \\): <br><br>\n$$\nF(x + \\Delta x) \\approx F(x) + g(x)^T \\Delta x + \\frac{1}{2} \\Delta x^T H(x) \\Delta x + \\dots\n$$\n<br><br>\n\nwhere: <br>\n\n- \\( g(x) \\) is the gradient of \\( F \\): <br><br>\n$$\ng = \\begin{bmatrix} \\frac{\\partial F}{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial F}{\\partial x_n} \\end{bmatrix}.\n$$\n\n<br><br>\n- \\( H(x) \\) is the Hessian matrix of second derivatives: <br><br>\n$$\nH =\n\\begin{bmatrix}\n\\frac{\\partial^2 F}{\\partial x_1^2} & \\cdots & \\frac{\\partial^2 F}{\\partial x_1 \\partial x_n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2 F}{\\partial x_n \\partial x_1} & \\cdots & \\frac{\\partial^2 F}{\\partial x_n^2}\n\\end{bmatrix}.\n$$\n<br><br>\nTruncating the series gives a quadratic approximation of \\( F(x) \\) around \\( x \\).",
    "front": "Taylor series for a vector-valued function \\( F(x) \\)",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "Positive definiteness of a real $n \\times n$ symmetric matrix $A$ is defined as <br><br>\n$$\nx^T A x > 0, \\quad \\forall x \\neq 0, \\; x \\in \\mathbb{R}^n\n$$",
    "front": "Positive definite (PD) <br><br>\nDefine<br><br>\nHow to test for it",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "meeting some necessary conditions does not mean the thing is true but its required that the condition be true when the thing is true. <br><br>\n\nsufficient condition when meant means the thing of interest is true.",
    "front": "Necessary vs. sufficient conditions",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "A positive definite (PD) Hessian guarantees a local minimum, while a positive semi-definite (PSD) Hessian is only necessary\u2014it does not confirm a minimum on its own.<br><br>\n\n\\[\n\\begin{array}{|c|c|c|c|}\n\\hline\n\\textbf{Condition} & \\textbf{Hessian Type} & \\textbf{What It Means} & \\textbf{Conclusion} \\\\\n\\hline\n\\text{Necessary} & \\text{Positive Semi-Definite (PSD)} & \\text{No negative curvature, but could be flat in some directions} & \\text{Local min possible, but not guaranteed} \\\\\n\\hline\n\\text{Sufficient} & \\text{Positive Definite (PD)} & \\text{Strictly upward curvature in all directions} & \\text{Guarantees a local min} \\\\\n\\hline\n\\end{array}\n\\]",
    "front": "Hessian necessary and sufficient conditions for a local minimum.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "$$\ng(x^*) = 0\n$$\n<br><br>\ngradient is zero.",
    "front": "Stationary point necessary condition.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "If $f: \\mathbb{R}^n \\to \\mathbb{R}$ is a differentiable function, the gradient of $f(x)$ is defined as:\n<br><br>\n\n$$\n\\nabla f(x) = \n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{bmatrix}.\n$$\n\n<br><br>\nEach component $\\frac{\\partial f}{\\partial x_i}$ represents the partial derivative of $f$ with respect to $x_i$.\n<br><br>\n\nThe gradient is a vector that points in the direction of the steepest increase of $f(x)$.",
    "front": "Define the gradient of $f(x)$.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "A functional is a mapping from a space of functions to the real numbers. <br><br>\n\nMathematically, a functional $J$ takes a function $y(x)$ as input and returns a real number:\n<br><br>\n\n$$\nJ[y] = \\int_{a}^{b} F(x, y, y') \\, dx.\n$$\n\n<br><br>\nFunctionals are commonly used in calculus of variations and physics to express quantities such as energy or action.",
    "front": "What is a <b>functional</b>?",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "The first variation of a functional is the first-order term in the Taylor expansion of the increment, providing a linear approximation of the change in the functional. <br><br>\n\nThe first variation of a functional $J[x(t)]$ with respect to a perturbation $\\delta x(t)$ is defined as:\n<br><br>\n\n$$\n\\delta J(x(t), \\delta x(t)) = \\left. \\frac{d}{d\\epsilon} J(x(t) + \\epsilon \\delta x(t)) \\right|_{\\epsilon=0}.\n$$\n<br><br>\n\n<b>TODO: fix beyond here to make more sense</b>\n<br><br>\n\nFor a functional $J[y]$, we express its perturbation as:\n<br><br>\n\n$$\nJ[y + \\epsilon \\delta y] = \\int_a^b F(x, y + \\epsilon \\delta y, y' + \\epsilon \\delta y') \\, dx.\n$$\n<br><br>\n\nExpanding $F( \\cdot )$ in a Taylor series around $\\epsilon = 0$ gives:\n<br><br>\n$$\nF(x, y + \\epsilon \\delta y, y' + \\epsilon \\delta y') = F(x, y, y') + \\epsilon \\left( \\frac{\\partial F}{\\partial y} \\delta y + \\frac{\\partial F}{\\partial y'} \\delta y' \\right) + O(\\epsilon^2).\n$$\n<br>\n\nSubstituting this into the integral:\n<br><br>\n$$\nJ[y + \\epsilon \\delta y] = J[y] + \\epsilon \\int_a^b \\left( \\frac{\\partial F}{\\partial y} \\delta y + \\frac{\\partial F}{\\partial y'} \\delta y' \\right) dx + O(\\epsilon^2).\n$$\n<br><br>\n\nTaking the limit as $\\epsilon \\to 0$, we obtain the first variation:\n<br><br>\n$$\n\\delta J = \\int_a^b \\left( \\frac{\\partial F}{\\partial y} \\delta y + \\frac{\\partial F}{\\partial y'} \\delta y' \\right) dx.\n$$\n<br>",
    "front": "What is the definition of an <b>increment</b>?",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "The first variation of functional is a linear approximation of the increment, i.e., first-order Taylor expansion of the increment.<br><br>\n\nThe **first variation** of a functional $J[x(t)]$ with respect to a perturbation $\\delta x(t)$ is defined as:\n<br><br>\n\n$$\n\\delta J(x(t), \\delta x(t)) = \\left. \\frac{d}{d\\epsilon} J(x(t) + \\epsilon \\delta x(t)) \\right|_{\\epsilon=0}.\n$$\n<br><br>\n\nFor a functional $J[y]$ and a small perturbation $\\delta y$, consider:\n<br><br>\n\n$$\nJ[y + \\epsilon \\delta y] = \\int_a^b F(x, y + \\epsilon \\delta y, y' + \\epsilon \\delta y') \\, dx.\n$$\n<br><br>\n\nExpanding the integrand $F( \\cdot )$ in a Taylor series around $\\epsilon = 0$, we obtain:\n<br><br>\n$$\nF(\\cdot) = F(x, y, y') + \\epsilon \\left( \\frac{\\partial F}{\\partial y} \\delta y + \\frac{\\partial F}{\\partial y'} \\delta y' \\right) + O(\\epsilon^2).\n$$\n<br><br>\n\nSubstituting this expansion back into the integral gives:\n<br><br>\n$$\nJ[y + \\epsilon \\delta y] = \\int_a^b \\Bigg[ F(x, y, y') + \\epsilon \\left( \\frac{\\partial F}{\\partial y} \\delta y + \\frac{\\partial F}{\\partial y'} \\delta y' \\right) + O(\\epsilon^2) \\Bigg] dx.\n$$\n<br>\n\nThis can be rewritten as:\n<br><br>\n$$\nJ[y + \\epsilon \\delta y] = J[y] + \\epsilon \\int_a^b \\left( \\frac{\\partial F}{\\partial y} \\delta y + \\frac{\\partial F}{\\partial y'} \\delta y' \\right) dx + O(\\epsilon^2).\n$$\n<br><br>\n\nThe first variation $\\delta J$ is defined as the first-order term:\n<br><br>\n$$\n\\delta J = \\lim_{\\epsilon \\to 0} \\frac{J[y + \\epsilon \\delta y] - J[y]}{\\epsilon} = \\int_a^b \\left( \\frac{\\partial F}{\\partial y} \\delta y + \\frac{\\partial F}{\\partial y'} \\delta y' \\right) dx.\n$$\n<br>",
    "front": "What is the definition of the <b>first variation</b>?",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "The Euler-Lagrange equation states that for a function $g(x, \\dot{x}, t)$:\n<br><br>\n\n$$\n\\frac{d}{dt} \\left( \\frac{\\partial g}{\\partial \\dot{x}} \\right) - \\frac{\\partial g}{\\partial x} = 0\n\n\\quad \\quad \\quad \\quad \\text{or} \\quad \\quad \\quad \\quad\n\n\\frac{d}{dt} \\left( \\frac{\\partial L}{\\partial \\dot{x}} \\right) - \\frac{\\partial L}{\\partial x} = 0\n$$\n\n<br><br>\nRewriting this:\n\n<br><br>\n$$\n\\frac{d}{dt} (g_{\\dot{x}}) - g_x = 0\n\n\\quad \\quad \\quad \\quad \\text{or} \\quad \\quad \\quad \\quad\n\n\\frac{d}{dt} (L_{\\dot{x}}) - L_x = 0\n$$\n\n<br><br>\nwhich is the fundamental condition for extremizing a functional in the calculus of variations.",
    "front": "Define and derive the <b>Euler-Lagrange equation</b>.\n<br><br>",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "$$\nH(x, u, \\lambda, t) = f(x, u, t) \\cdot \\lambda + L(x, u, t).\n$$\n<br><br>\nwhere: <br>\n- x  is the state variable. <br>\n- u  is the control variable. <br>\n- \\lambda  is the costate (adjoint) variable (analogous to momentum in classical mechanics). <br>\n- L(x, u, t)  is the running cost.<br>\n- f(x, u, t)  describes the system dynamics.\n\n<br><br><br><br>\n$$\nH = \\dot{x} \\frac{\\partial L}{\\partial \\dot{x}} - L \n  \\quad \\text{or} \\quad \nH = \\dot{x} \\frac{\\partial g}{\\partial \\dot{x}} - g\n$$\n<br><br>\nRewriting as:<br><br>\n$$\nH = \\dot{x} L_{\\dot{x}} - L \n  \\quad \\text{or} \\quad \nH = \\dot{x} g_{\\dot{x}} - g\n$$\n\n<br><br>\n\nNote that:<br><br>\n$$\ng_t + \\frac{dH}{dt} = 0.\n$$\n\n<br><br>\nThe crucial property of the Hamiltonian is that:<br>\n- If  $L$  does not explicitly depend on time (i.e.,  $L_t = 0$ ), then  $H$  is conserved.<br>\n- This leads directly to the Beltrami identity, which states that:\n$$\n\\dot{x} g_{\\dot{x}} - g = \\text{constant}.\n$$",
    "front": "Hamiltonian",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "$$\n\\min_{x \\in \\mathbb{R}^{n}}{f(x)}\n$$\n<br><br>\nsubject to: <br>\n$$\ng_{i}(x) \\leq 0, \\quad i \\in \\mathcal{I}, \\quad \\mathcal{I} = 1, \\dots, m \\quad \\text{(inequality constraints)}\n$$\n<br>\n$$\nh_{i}(x) = 0, \\quad j \\in \\mathcal{E}, \\quad \\mathcal{E} = 1, \\dots, p \\quad \\; \\text{(equality constraints)}\n$$\n<br><br>\nwhere:\n<ul>\n  <li>$$f(x)$$ is the objective function to be minimized.</li>\n  <li>$$g_i(x) \\leq 0$$ represents inequality constraints that must be satisfied.</li>\n  <li>$$h_j(x) = 0$$ represents equality constraints that must be exactly satisfied.</li>\n  <li>$$x \\in \\mathbb{R}^n$$ is the decision variable (a vector in \\( n \\)-dimensional space).</li>\n</ul>",
    "front": "Standard form of a constrained optimization problem.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "<ol>\n\n  <li>Stationarity <br>\n    $$\n    \\nabla f(x^*) + \\sum_{i \\in \\mathcal{A}} \\lambda_i \\nabla g_i(x^*) + \\sum_{j=1}^{p} \\mu_j \\nabla h_j(x^*) = 0\n    $$\n  </li>\n  <br>\n\n  <li>Primal feasibility <br>\n    $$\n    g_i(x^*) \\leq 0, \\quad \\forall i \\in \\{1, \\dots, m\\}\n    $$\n    <br>\n    $$\n    h_j(x^*) = 0, \\quad \\forall j \\in \\{1, \\dots, p\\}\n    $$\n  </li>\n  <br>\n\n  <li>Dual feasibility <br>\n    $$\n    \\lambda_i \\geq 0, \\quad \\forall i \\in \\{1, \\dots, m\\}\n    $$\n  </li>\n  <br>\n\n  <li>Complementary slackness <br>\n    $$\n    \\lambda_i g_i(x^*) = 0, \\quad \\forall i \\in \\{1, \\dots, m\\}\n    $$\n  </li>\n  <br>\n\n</ol>",
    "front": "KKT Conditions.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "When the gradients of the active constraints are linearly dependent\u2014that is, when the Linear Independence Constraint Qualification (LICQ) fails. In this case, the constraint gradients do not span enough directions to cancel out the gradient of the objective, meaning the stationarity condition cannot be met.",
    "front": "Under what circumstances can we fail to choose Lagrange multipliers that satisfy the KKT conditions without contradiction?",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "At an optimal point $x^*$, the idea is that no small, feasible perturbation $d$ should be able to decrease the objective function. In other words, for every feasible direction $d$, we must have <br><br>\n\n$$\n\\nabla f(x^{*})^T d \\geq 0.\n$$\n\n<br><br>\nNow, when a constraint $g_i(x) \\leq 0$ is active (i.e. $g_i(x^*) = 0)$, any small movement d that keeps us feasible must satisfy <br><br>\n$$\n\\nabla g_i(x^{*})^T d \\leq 0.\n$$\n<br><br>\nThis means the feasible directions are limited by the gradients of the active constraints. For there to be no feasible descent direction\u2014that is, for the objective not to decrease along any $d$\u2014the entire gradient $\\nabla f(x^*)$ must be \u201cneutralized\u201d by the constraint forces. This requirement is captured by the stationarity condition: <br><br>\n$$\n\\nabla f(x^*) + \\sum_{i \\in \\mathcal{A}} \\lambda_i \\nabla g_i(x^*) = 0.\n$$\n<br><br>\nHere, the multipliers $\\lambda_i$ adjust the contribution of each constraint\u2019s gradient so that they together cancel out $\\nabla f(x^*)$. This ensures that any movement allowed by the constraints does not provide a descent direction, preserving the optimality of $x^*$.\n<br>",
    "front": "Why must the stationarity condition hold at an optimal solution in constrained optimization?",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "At an optimal point $x^*$, the gradients of the active constraints, $\\nabla g_i(x^*)$ for all $i$ such that $g_i(x^*) = 0$, define the normal (or \u201cblocking\u201d) directions at $x^*$. They essentially tell us which directions are forbidden for movement if we want to remain feasible. <br><br>\n\nFor $x^*$ to be optimal, the gradient $\\nabla f(x^*)$ must not point in any direction that would allow us to decrease $f(x)$ while staying within the feasible region. This is only possible if $\\nabla f(x^*)$ lies entirely in the span of the constraint gradients. In mathematical terms, this means that there exist multipliers $\\lambda_i$ such that <br><br>\n\n$$\n\\nabla f(x^*) = -\\sum_{i \\in \\mathcal{A}} \\lambda_i \\nabla g_i(x^*).\n$$\n\n<br><br>\nIf any component of $\\nabla f(x^*)$ were to lie outside of the span of the $\\nabla g_i(x^*)$, then there would be a feasible direction in which $f(x)$ could decrease, contradicting the optimality of $x^*$. <br><br>\n\nThus, the condition guarantees that all possible descent directions are \u201cblocked\u201d by the active constraints, ensuring that $x^*$ is indeed optimal.",
    "front": "What is the geometric intuition behind the KKT stationarity condition?",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "The LICQ condition states that at a feasible point $x^*$, the gradients of all active constraints must be linearly independent. <br><br>\n\nMathematically, if the set of active constraints at $x^*$ is given by:\n<br><br>\n$$\n\\mathcal{A} = \\{ i \\mid g_i(x^*) = 0 \\},\n$$\n<br><br>\nthen the gradients of these constraints,\n<br><br>\n$$\n\\{ \\nabla g_i(x^*) \\}_{i \\in \\mathcal{A}},\n$$\n<br><br>\nmust be linearly independent. This means that if there exists a set of scalars $\\lambda_i$ such that:\n<br><br>\n$$\n\\sum_{i \\in \\mathcal{A}} \\lambda_i \\nabla g_i(x^*) = 0,\n$$\n<br><br>\nthen it must follow that $\\lambda_i = 0$ for all $i \\in \\mathcal{A}$. <br><br>\n\nIf LICQ holds, then the active constraint gradients span a well-defined space, ensuring that the KKT conditions hold without contradiction. <br><br>\n\nIf LICQ fails, the stationarity condition may not be satisfied, meaning no valid Lagrange multipliers exist.",
    "front": "Linear Independence Constraint Qualification (LICQ) condition.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "Collocation points.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content",
    "front": "Interpolation points.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "General way to express most optimal control problems: <br><br>\n\n\\[\n\\begin{array}{ll}\n\\textbf{Minimize} & J = \\phi\\Bigl(x(t_0),\\, x(t_f),\\, t_0,\\, t_f,\\, q,\\, s\\Bigr) \\\\\n\\\\\n\\textbf{with respect to} & x(t),\\; u(t),\\; t_0,\\; t_f,\\; s,\\; q \\\\\n\\\\\n\\textbf{subject to} & \\dot{x}(t) = f\\Bigl(x(t),\\, u(t),\\, t,\\, s\\Bigr), \\quad t \\in [t_0, t_f], \\\\\n\\\\\n& q = \\int_{t_0}^{t_f} g\\Bigl(x(t),\\, u(t),\\, t,\\, s\\Bigr) dt, \\\\\n\\\\\n& c\\Bigl(x(t),\\, u(t),\\, t,\\, s\\Bigr) \\le 0, \\quad t \\in [t_0, t_f], \\\\\n\\\\\n& \\psi\\Bigl(x(t_0),\\, x(t_f),\\, t_0,\\, t_f,\\, s\\Bigr) = 0, \\\\\n\\\\\n& \\text{and appropriate bounds on } x(t),\\, u(t),\\, s,\\, t_0,\\, t_f.\n\\end{array}\n\\]",
    "front": "Bolza optimization problem formulation.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content\n\n<br><br>\nThe following functions are transcendental:<br>\n<img src=\"/assets/Screenshot_2025-02-28_at_1.31.02_AM.png\">",
    "front": "Transcendental equation",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content <br><br>\n\nWhat is it and what is the equation for it?",
    "front": "Catenary curve.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  },
  {
    "back": "TODO: New back content <br><br>\n\nWhat is it and what is the equation for it?",
    "front": "Catenoid.",
    "importance": 2,
    "tags": [
      "16.32"
    ],
    "understanding": 1
  }
]