[
  {
    "front": "Orthogonal Matrices",
    "back": "$Q^T = Q^{-1}$. The columns and rows of $Q$ form an orthonormal set, meaning each has unit length and is mutually perpendicular. Multiplying by $Q$ preserves vector norms.",
    "importance": 7,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 4
  },
  {
    "front": "Symmetric Matrices",
    "back": "A symmetric matrix is one that satisfies $A = A^T$.<br><br>Key properties include:<br><ul><li>All eigenvalues are real.</li><li>It can be diagonalized by an orthogonal matrix.</li><li>Its quadratic form is always real.</li></ul>",
    "importance": 6,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 3
  },
  {
    "front": "Eigenvector and value",
    "back": "$Qx = \\lambda x$",
    "importance": 10,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 6
  },
  {
    "front": "Inner product",
    "back": "An inner product on a vector space is a function that assigns a scalar to a pair of vectors. In $\\mathbb{R}^n$, the standard inner product is $x \\cdot y = \\sum_{i=1}^{n} x_i y_i$, which satisfies linearity, symmetry, and positive definiteness.",
    "importance": 5,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 2
  },
  {
    "front": "Outter product",
    "back": "The outer product of two vectors $x$ and $y$ is the matrix $xy^T$. This produces a rank-one matrix that is useful for constructing projections and low-rank approximations.",
    "importance": 5,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 2
  },
  {
    "front": "$ (AB)^{-1} = \\;\\;? $",
    "back": "$ (AB)^{-1} = B^{-1} A^{-1}$",
    "importance": 5,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 7
  },
  {
    "front": "LU Decomposition",
    "back": "The LU decomposition factors a square matrix $A$ into the product of a lower triangular matrix $L$ and an upper triangular matrix $U$, such that $A = LU$. This decomposition is useful for solving linear systems and numerical stability.",
    "importance": 5,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 4
  },
  {
    "front": "QR Decomposition",
    "back": "The QR decomposition expresses a matrix $A$ as the product of an orthogonal matrix $Q$ and an upper triangular matrix $R$, such that $A = QR$. This is commonly used in least squares solutions and eigenvalue algorithms.",
    "importance": 5,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 5
  },
  {
    "front": "Spectral Theorem (for symmetric matrices)",
    "back": "For any real symmetric matrix $S$, there exists an orthogonal matrix $Q$ and a diagonal matrix $\\Lambda$ such that $S = Q \\Lambda Q^T$. This means symmetric matrices can be diagonalized by an orthogonal transformation.",
    "importance": 5,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 6
  },
  {
    "front": "Eigen Decomposition",
    "back": "The eigen decomposition expresses a diagonalizable matrix $A$ as $A = X \\Lambda X^{-1}$, where $X$ is the matrix of eigenvectors and $\\Lambda$ is the diagonal matrix of eigenvalues.",
    "importance": 5,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 7
  },
  {
    "front": "Singular Value Decomposition (SVD)",
    "back": "The singular value decomposition (SVD) of a matrix $A$ is given by $A = U \\Sigma V^T$, where $U$ and $V$ are orthogonal matrices, and $\\Sigma$ is a diagonal matrix containing singular values. This is widely used in dimensionality reduction and numerical analysis.",
    "importance": 5,
    "tags": ["linear algebra", "18.0651"],
    "understanding": 7
  }
]